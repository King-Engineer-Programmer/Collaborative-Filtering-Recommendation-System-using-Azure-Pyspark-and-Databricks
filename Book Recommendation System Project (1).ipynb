{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a466e4-25c1-496b-8ea5-a44e47567033",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connecting notebook with Storage Account\n",
    "\n",
    "# spark.conf.set(\n",
    "# \"fs.azure.account.key.<storage-account>.dfs.core.windows.net\",\n",
    "# \"<storage account key>\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4338c236-0f98-40da-b569-60b317198fba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Define the path to the ADLS Gen2 storage container\n",
    "# adls_path = \"abfss://<target-container>@<storage-account>.dfs.core.windows.net/\"\n",
    "\n",
    "# # Use dbutils.fs.ls to list the contents of the specified path\n",
    "# contents = dbutils.fs.ls(adls_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebb435e0-bea3-42b1-8be7-7e0041e37912",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abccb5d7-25a0-4955-820c-06e2c6cf9d47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, desc, isnull, mean, when, explode\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Initialize the Spark session\n",
    "spark = SparkSession.builder.appName(\"Book Recommendation System\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ddeb37-9fa7-478a-9e0e-f35449ddfe23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the storage container\n",
    "adls_path = \" \"\n",
    "\n",
    "# Load Books dataset \n",
    "books_df = spark.read.csv(adls_path + 'Books.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Load Ratings dataset \n",
    "ratings_df = spark.read.csv(adls_path + 'Ratings.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Load Users dataset \n",
    "users_df = spark.read.csv(adls_path + 'Users.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d258e4a4-1e70-4ab7-8b36-d4b314f05cc6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac991d4d-53f2-4af8-92ae-6e3889ae30f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books dataset statistics:\n+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|summary|                ISBN|          Book-Title|         Book-Author| Year-Of-Publication|           Publisher|         Image-URL-S|         Image-URL-M|         Image-URL-L|\n+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|  count|              271360|              271360|              271359|              271360|              271358|              271360|              271360|              271357|\n|   mean|1.0412234356977516E9|            Infinity|              2001.0|   1959.754171535147|  3765.6153846153848|             1992.25|              1984.5|             1988.25|\n| stddev|1.4877142833957233E9|                -NaN|  1.7320508075688772|   258.0194498067871|  7963.0591536808415|   9.863845829363598|  0.7071067811865476|    7.13559154286923|\n|    min|          0000913154| A Light in the S...| 15th Illinois Vo...|                1961| As Taught at the...| 1865. (Collector...|          Bill Stern|       Our Miss b\"\"\"|\n|    max|          B0002K6K8O|   Ã?Â?thique en toc|      Ã?Â?ric Holder|and the Final Rid...|      Ã?Â¶bv&amp;hpt|http://images.ama...|http://images.ama...|http://images.ama...|\n+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n\nRatings dataset statistics:\n+-------+------------------+-----------+------------------+\n|summary|           User-ID|       ISBN|       Book-Rating|\n+-------+------------------+-----------+------------------+\n|  count|           1149780|    1149780|           1149780|\n|   mean|140386.39512602412|   Infinity|2.8669501991685364|\n| stddev| 80562.27771851212|       -NaN|3.8541838592016546|\n|    min|                 2| 0330299891|                 0|\n|    max|            278854|  Ô½crosoft|                10|\n+-------+------------------+-----------+------------------+\n\nUsers dataset statistics:\n+-------+-----------------+------------------+------------------+\n|summary|          User-ID|          Location|               Age|\n+-------+-----------------+------------------+------------------+\n|  count|           278858|            278859|            168341|\n|   mean|         139429.5|              NULL|34.751833915812824|\n| stddev|80499.51502027822|              NULL| 14.43101026844749|\n|    min|                1|             milan| \\\"\"alexandria\\\"\".|\n|    max|           278858|ýzmýr, n/a, turkey|              99.0|\n+-------+-----------------+------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics for the Books dataset\n",
    "print(\"Books dataset statistics:\")\n",
    "books_df.describe().show()\n",
    "\n",
    "# Display basic statistics for the Ratings dataset\n",
    "print(\"Ratings dataset statistics:\")\n",
    "ratings_df.describe().show()\n",
    "\n",
    "# Display basic statistics for the Users dataset\n",
    "print(\"Users dataset statistics:\")\n",
    "users_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23726837-38cb-4a59-ad2f-ede24fad6f2a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75596699-51d6-4d99-b0a8-6d07cac5153b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Books dataset:\n+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n|ISBN|Book-Title|Book-Author|Year-Of-Publication|Publisher|Image-URL-S|Image-URL-M|Image-URL-L|\n+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n|   0|         0|          1|                  0|        2|          0|          0|          3|\n+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n\nMissing values in Ratings dataset:\n+-------+----+-----------+\n|User-ID|ISBN|Book-Rating|\n+-------+----+-----------+\n|      0|   0|          0|\n+-------+----+-----------+\n\nMissing values in Users dataset:\n+-------+--------+------+\n|User-ID|Location|   Age|\n+-------+--------+------+\n|      1|       0|110518|\n+-------+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing values in each column of the Books dataset\n",
    "print(\"Missing values in Books dataset:\")\n",
    "books_df.select([count(when(isnull(c), c)).alias(c) for c in books_df.columns]).show()\n",
    "\n",
    "# Calculate missing values in each column of the Ratings dataset\n",
    "print(\"Missing values in Ratings dataset:\")\n",
    "ratings_df.select([count(when(isnull(c), c)).alias(c) for c in ratings_df.columns]).show()\n",
    "\n",
    "# Calculate missing values in each column of the Users dataset\n",
    "print(\"Missing values in Users dataset:\")\n",
    "users_df.select([count(when(isnull(c), c)).alias(c) for c in users_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "add24978-2d09-41c2-be84-b9b1d34890d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Missing Values in Book Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2d4833-f486-4a4c-9cbe-db5e2d7c554c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handled missing values in Books dataset.\n"
     ]
    }
   ],
   "source": [
    "# Removing rows with missing ISBNs, Book-Title, Book-Author, or Publisher\n",
    "books_df = books_df.dropna(subset=[\"ISBN\", \"Book-Title\", \"Book-Author\", \"Publisher\"])\n",
    "\n",
    "# Fill missing Year-Of-Publication with a placeholder value such as -1\n",
    "books_df = books_df.fillna({\"Year-Of-Publication\": -1})\n",
    "\n",
    "# Fill missing image URLs with a default URL or leave them as is\n",
    "# Example: books_df = books_df.fillna({\"Image-URL-S\": \"default_url\", \"Image-URL-M\": \"default_url\", \"Image-URL-L\": \"default_url\"})\n",
    "\n",
    "print(\"Handled missing values in Books dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3893b731-99c8-4f2a-96dc-09d7e99acb98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Missing Values in the Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eae45292-f404-41fa-9c45-83250b3f1b87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handled missing values in Ratings dataset.\n"
     ]
    }
   ],
   "source": [
    "# Removing rows with missing User-ID, ISBN, or Book-Rating\n",
    "ratings_df = ratings_df.dropna(subset=[\"User-ID\", \"ISBN\", \"Book-Rating\"])\n",
    "\n",
    "print(\"Handled missing values in Ratings dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b0036e9-7874-42b2-9b6b-20b7b00fbcf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Missing Values in Users Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d851cb79-31f4-4d06-bf44-786c681d8157",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handled missing values in Users dataset.\n"
     ]
    }
   ],
   "source": [
    "# Removing rows with missing User-ID\n",
    "users_df = users_df.dropna(subset=[\"User-ID\"])\n",
    "\n",
    "# Replace missing location with a placeholder value, such as \"Unknown\"\n",
    "users_df = users_df.fillna({\"Location\": \"Unknown\"})\n",
    "\n",
    "# Replace missing Age with the mean age (you can also use median)\n",
    "mean_age = users_df.select(F.mean(\"Age\")).first()[0]\n",
    "users_df = users_df.fillna({\"Age\": mean_age})\n",
    "\n",
    "print(\"Handled missing values in Users dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cf6c42d-68a3-45ec-a8dc-a5b6940591dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Checking Dataset after cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c33fad-afe5-489e-b891-4348de060ae7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Books dataset:\n+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n|ISBN|Book-Title|Book-Author|Year-Of-Publication|Publisher|Image-URL-S|Image-URL-M|Image-URL-L|\n+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n|   0|         0|          0|                  0|        0|          0|          0|          3|\n+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n\nMissing values in Ratings dataset:\n+-------+----+-----------+\n|User-ID|ISBN|Book-Rating|\n+-------+----+-----------+\n|      0|   0|          0|\n+-------+----+-----------+\n\nMissing values in Users dataset:\n+-------+--------+---+\n|User-ID|Location|Age|\n+-------+--------+---+\n|      0|       0|  0|\n+-------+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing values in each column of the Books dataset\n",
    "print(\"Missing values in Books dataset:\")\n",
    "books_df.select([count(when(isnull(c), c)).alias(c) for c in books_df.columns]).show()\n",
    "\n",
    "# Calculate missing values in each column of the Ratings dataset\n",
    "print(\"Missing values in Ratings dataset:\")\n",
    "ratings_df.select([count(when(isnull(c), c)).alias(c) for c in ratings_df.columns]).show()\n",
    "\n",
    "# Calculate missing values in each column of the Users dataset\n",
    "print(\"Missing values in Users dataset:\")\n",
    "users_df.select([count(when(isnull(c), c)).alias(c) for c in users_df.columns]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92ff578a-e6b9-4199-868e-7bd8cd1b94af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Checking the Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "322aaa97-db5f-4aa2-9560-8aa8c3bdf4e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books dataset size:\n(271357, 8)\nRatings dataset size:\n(1149780, 3)\n(278858, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows and columns in the Books dataset\n",
    "print(\"Books dataset size:\")\n",
    "print((books_df.count(), len(books_df.columns)))\n",
    "\n",
    "# Calculate the number of rows and columns in the Ratings dataset\n",
    "print(\"Ratings dataset size:\")\n",
    "print((ratings_df.count(), len(ratings_df.columns)))\n",
    "\n",
    "# Calculate the number of rows and columns in the Users dataset\n",
    "print((users_df.count(), len(users_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfefc99c-4b6d-4b63-a3a1-6e63ff0bb26b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Books Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da5801f3-d86c-4936-8b32-d17005467cba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-Of-Publication distribution:\n+--------------------+-----+\n| Year-Of-Publication|count|\n+--------------------+-----+\n|                1961|    1|\n|              D.S.O.|    1|\n| Internet (La cou...|    1|\n|          Mary Noble|    1|\n|    Relationships\"\"\"|    1|\n| Slimmer--And How...|    1|\n| \\\"\"The School fo...|    1|\n| acht unpaginiert...|    1|\n| and Anti-Environ...|    1|\n| and Box-Office M...|    1|\n| and Murder (St. ...|    1|\n| and Musicians at...|    1|\n|           and River|    1|\n|         and Text\"\"\"|    1|\n| and \\\"\"I\\\"\" Is f...|    1|\n| and tasty! : com...|    1|\n| samtaler med PÃ¤...|    1|\n|\"Del \\Irish\"\" Mea...|    1|\n|                   0| 4618|\n|                1376|    1|\n+--------------------+-----+\nonly showing top 20 rows\n\nTop Publishers:\n+--------------------+-----+\n|           Publisher|count|\n+--------------------+-----+\n|           Harlequin| 7533|\n|          Silhouette| 4220|\n|              Pocket| 3905|\n|    Ballantine Books| 3782|\n|        Bantam Books| 3645|\n|          Scholastic| 3159|\n|Simon &amp; Schuster| 2969|\n|       Penguin Books| 2843|\n|Berkley Publishin...| 2771|\n|        Warner Books| 2727|\n+--------------------+-----+\nonly showing top 10 rows\n\nLength of book titles:\n+-------+-----------------+\n|summary|     title_length|\n+-------+-----------------+\n|  count|           271357|\n|   mean|37.83079485695965|\n| stddev|25.20519001312427|\n|    min|                1|\n|    max|              259|\n+-------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of Year-Of-Publication\n",
    "print(\"Year-Of-Publication distribution:\")\n",
    "books_df.groupBy(\"Year-Of-Publication\").count().orderBy(\"Year-Of-Publication\").show()\n",
    "\n",
    "# Identify the top publishers based on the number of books published\n",
    "print(\"Top Publishers:\")\n",
    "books_df.groupBy(\"Publisher\").count().orderBy(desc(\"count\")).show(10)\n",
    "\n",
    "# Analyze the length of book titles and summarize the statistics\n",
    "print(\"Length of book titles:\")\n",
    "books_df.withColumn(\"title_length\", F.length(col(\"Book-Title\"))).describe(\"title_length\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d28e31a6-f7e6-4c4b-a9f2-bb995b531c9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Year of Publication Data Cleaning and Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c48689-efe1-44fc-ba9f-8b429963f98a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and converted Year-Of-Publication to integer in Books dataset\n"
     ]
    }
   ],
   "source": [
    "# Clean and convert Year-Of-Publication in Books dataset to integer\n",
    "def clean_year_of_publication(df):\n",
    "    df = df.filter((df[\"Year-Of-Publication\"].cast(\"int\").isNotNull()) & \n",
    "                   (df[\"Year-Of-Publication\"].cast(\"int\") >= 1800) & \n",
    "                   (df[\"Year-Of-Publication\"].cast(\"int\") <= 2023))\n",
    "    return df.withColumn(\"Year-Of-Publication\", df[\"Year-Of-Publication\"].cast(\"int\"))\n",
    "\n",
    "books_df = clean_year_of_publication(books_df)\n",
    "print(\"Cleaned and converted Year-Of-Publication to integer in Books dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b5fe8dd-21f4-4047-a92b-91c14aaa03be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-Of-Publication distribution:\n+-------------------+-----+\n|Year-Of-Publication|count|\n+-------------------+-----+\n|               1806|    1|\n|               1897|    1|\n|               1900|    3|\n|               1901|    7|\n|               1902|    2|\n|               1904|    1|\n|               1906|    1|\n|               1908|    1|\n|               1909|    2|\n|               1910|    1|\n|               1911|   19|\n|               1914|    1|\n|               1917|    1|\n|               1919|    1|\n|               1920|   33|\n|               1921|    2|\n|               1922|    2|\n|               1923|   11|\n|               1924|    2|\n|               1925|    2|\n+-------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of Year-Of-Publication\n",
    "print(\"Year-Of-Publication distribution:\")\n",
    "books_df.groupBy(\"Year-Of-Publication\").count().orderBy(\"Year-Of-Publication\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e323d746-1ae9-4a85-b03b-9c0d328e46de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Duplicate Book Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a7a570-6906-41b4-a21f-e8aac1979d06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate entries in Books dataset:\nNumber of duplicate entries in Books dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate entries in the Books dataset\n",
    "print(\"Checking for duplicate entries in Books dataset:\")\n",
    "duplicates = books_df.groupBy(\"ISBN\").count().filter(col(\"count\") > 1)\n",
    "print(f\"Number of duplicate entries in Books dataset: {duplicates.count()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d5c3e12-0917-4fca-b077-7b523157dfd8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e88b5154-dc0f-4e67-9644-746b32af63e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Book Ratings Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb586a4a-3bf8-4288-b9ee-21846b3dfaf7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings distribution:\n+-----------+------+\n|Book-Rating| count|\n+-----------+------+\n|          0|716109|\n|          1|  1770|\n|          2|  2759|\n|          3|  5996|\n|          4|  8904|\n|          5| 50974|\n|          6| 36924|\n|          7| 76457|\n|          8|103736|\n|          9| 67541|\n|         10| 78610|\n+-----------+------+\n\nTop rated books by average rating:\n+----------+--------------+\n|      ISBN|average_rating|\n+----------+--------------+\n|0690041535|          10.0|\n|067088782X|          10.0|\n|0425105156|          10.0|\n|0525938508|          10.0|\n|0945367198|          10.0|\n|0859051595|          10.0|\n|0394731271|          10.0|\n|1886411999|          10.0|\n|080482052X|          10.0|\n|9707100567|          10.0|\n+----------+--------------+\nonly showing top 10 rows\n\nUser rating activity:\n+-------+-----+\n|User-ID|count|\n+-------+-----+\n|  11676|13602|\n| 198711| 7550|\n| 153662| 6109|\n|  98391| 5891|\n|  35859| 5850|\n| 212898| 4785|\n| 278418| 4533|\n|  76352| 3367|\n| 110973| 3100|\n| 235105| 3067|\n+-------+-----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of ratings\n",
    "print(\"Ratings distribution:\")\n",
    "ratings_df.groupBy(\"Book-Rating\").count().orderBy(\"Book-Rating\").show()\n",
    "\n",
    "# Identify the top-rated books by average rating\n",
    "print(\"Top rated books by average rating:\")\n",
    "ratings_df.groupBy(\"ISBN\").agg(mean(\"Book-Rating\").alias(\"average_rating\")).orderBy(desc(\"average_rating\")).show(10)\n",
    "\n",
    "# Examine user rating activity by counting ratings per user\n",
    "print(\"User rating activity:\")\n",
    "ratings_df.groupBy(\"User-ID\").count().orderBy(desc(\"count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbf79d0a-0d90-4315-84a9-f8560f5f1c3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Users Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8933e246-bd82-4a8c-8ded-1038be1b9039",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User age distribution:\n+------------------+-----+\n|               Age|count|\n+------------------+-----+\n| \\\"\"alexandria\\\"\".|    1|\n|         \\\"\"n/a\\\"\"|    3|\n|      \\\"\"n/a\\\"\"\"\"\"|    1|\n|        andorra\"\"\"|    2|\n|      argentina\"\"\"|    5|\n|            athens|    1|\n|      australia\"\"\"|    1|\n|        austria\"\"\"|   13|\n|     bangladesh\"\"\"|    5|\n|        belgium\"\"\"|    4|\n|         brazil\"\"\"|    7|\n|          burma\"\"\"|    1|\n|     cape verde\"\"\"|    2|\n|          chile\"\"\"|    5|\n|          china\"\"\"|    2|\n|       colombia\"\"\"|    3|\n|     costa rica\"\"\"|    2|\n|  cote d`ivoire\"\"\"|    1|\n|        croatia\"\"\"|    5|\n| czech republic\"\"\"|    3|\n+------------------+-----+\nonly showing top 20 rows\n\nUser location distribution:\n+--------------------+-----+\n|            Location|count|\n+--------------------+-----+\n|london, england, ...| 2506|\n|toronto, ontario,...| 2250|\n|sydney, new south...| 1744|\n|melbourne, victor...| 1708|\n|portland, oregon,...| 1629|\n|chicago, illinois...| 1526|\n|seattle, washingt...| 1484|\n|new york, new yor...| 1411|\n|madrid, madrid, s...| 1400|\n|vancouver, britis...| 1359|\n+--------------------+-----+\nonly showing top 10 rows\n\nUsers with missing age:\n+-------+--------+---+\n|User-ID|Location|Age|\n+-------+--------+---+\n+-------+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of user ages\n",
    "print(\"User age distribution:\")\n",
    "users_df.groupBy(\"Age\").count().orderBy(\"Age\").show()\n",
    "\n",
    "# Analyze the geographic distribution of users by location\n",
    "print(\"User location distribution:\")\n",
    "users_df.groupBy(\"Location\").count().orderBy(desc(\"count\")).show(10)\n",
    "\n",
    "# Identify users with missing age values\n",
    "print(\"Users with missing age:\")\n",
    "users_df.filter(users_df.Age.isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a7bf8ef-5006-482f-9b1a-56c91dbf3f7c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Age Data Cleaning and Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef53270-5167-45b7-bfb8-0188cbca9ce0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and converted Age to integer in Users dataset\n"
     ]
    }
   ],
   "source": [
    "# Clean and convert Age in Users dataset to integer\n",
    "def clean_age(df):\n",
    "    # Filter out records with invalid age values (e.g., strings or ages outside a reasonable range)\n",
    "    df = df.filter((df[\"Age\"].cast(\"int\").isNotNull()) & \n",
    "                   (df[\"Age\"].cast(\"int\") >= 5) & \n",
    "                   (df[\"Age\"].cast(\"int\") <= 120))\n",
    "    # Convert the column to integer type\n",
    "    return df.withColumn(\"Age\", df[\"Age\"].cast(\"int\"))\n",
    "\n",
    "users_df = clean_age(users_df)\n",
    "print(\"Cleaned and converted Age to integer in Users dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9804b22-5bdb-4b4c-a8a4-04f8b135805f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User age distribution:\n+---+-----+\n|Age|count|\n+---+-----+\n|  5|   26|\n|  6|   18|\n|  7|   27|\n|  8|   54|\n|  9|   62|\n| 10|   84|\n| 11|  121|\n| 12|  192|\n| 13|  883|\n| 14| 1962|\n| 15| 2379|\n| 16| 2566|\n| 17| 3042|\n| 18| 3690|\n| 19| 3934|\n| 20| 4040|\n| 21| 4428|\n| 22| 4701|\n| 23| 5440|\n| 24| 5666|\n+---+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of user ages\n",
    "print(\"User age distribution:\")\n",
    "users_df.groupBy(\"Age\").count().orderBy(\"Age\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dc486be-8e77-4c65-a3b2-afdc596263d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Join DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9832c8ca-dfba-4214-b376-713c128d26ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books dataset statistics and data types:\n\nData types in Books dataset:\n[('ISBN', 'string'), ('Book-Title', 'string'), ('Book-Author', 'string'), ('Year-Of-Publication', 'int'), ('Publisher', 'string'), ('Image-URL-S', 'string'), ('Image-URL-M', 'string'), ('Image-URL-L', 'string')]\n\nSummary statistics for Books dataset:\n+-------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n|summary|                ISBN|          Book-Title|         Book-Author|Year-Of-Publication|           Publisher|         Image-URL-S|         Image-URL-M|         Image-URL-L|\n+-------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n|  count|              266667|              266667|              266667|             266667|              266667|              266667|              266667|              266667|\n|   mean|1.0301034814177269E9|            Infinity|                NULL| 1993.6925041343698|  25032.333333333332|                NULL|                NULL|              1984.0|\n| stddev|1.4697071331971295E9|                -NaN|                NULL|  8.148267049506192|   21676.03850645531|                NULL|                NULL|                NULL|\n|    min|          0000913154| A Light in the S...| 15th Illinois Vo...|               1806| Editions P. Terrail| 1865. (Collector...|       Lucius Barber|                1984|\n|    max|          B000234NC6|   Ã?Â?thique en toc|      Ã?Â?ric Holder|               2021|      Ã?Â¶bv&amp;hpt|http://images.ama...|http://images.ama...|http://images.ama...|\n+-------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n\n\nRatings dataset statistics and data types:\n\nData types in Ratings dataset:\n[('User-ID', 'int'), ('ISBN', 'string'), ('Book-Rating', 'int')]\n\nSummary statistics for Ratings dataset:\n+-------+------------------+-----------+------------------+\n|summary|           User-ID|       ISBN|       Book-Rating|\n+-------+------------------+-----------+------------------+\n|  count|           1149780|    1149780|           1149780|\n|   mean|140386.39512602412|   Infinity|2.8669501991685364|\n| stddev| 80562.27771851212|       -NaN|3.8541838592016546|\n|    min|                 2| 0330299891|                 0|\n|    max|            278854|  Ô½crosoft|                10|\n+-------+------------------+-----------+------------------+\n\n\nUsers dataset statistics and data types:\n\nData types in Users dataset:\n[('User-ID', 'int'), ('Location', 'string'), ('Age', 'int')]\n\nSummary statistics for Users dataset:\n+-------+-----------------+--------------------+------------------+\n|summary|          User-ID|            Location|               Age|\n+-------+-----------------+--------------------+------------------+\n|  count|           277233|              277233|            277233|\n|   mean|139426.0610785873|                NULL| 34.52158653551345|\n| stddev|80491.24276961957|                NULL|10.808912605417639|\n|    min|                1|&#19978;&#28023;,...|                 5|\n|    max|           278858|  ýzmýr, n/a, turkey|               119|\n+-------+-----------------+--------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics and data types for the Books dataset\n",
    "print(\"Books dataset statistics and data types:\")\n",
    "print(\"\\nData types in Books dataset:\")\n",
    "print(books_df.dtypes)  # Display data types of columns\n",
    "print(\"\\nSummary statistics for Books dataset:\")\n",
    "books_df.describe().show()\n",
    "\n",
    "# Display basic statistics and data types for the Ratings dataset\n",
    "print(\"\\nRatings dataset statistics and data types:\")\n",
    "print(\"\\nData types in Ratings dataset:\")\n",
    "print(ratings_df.dtypes)  # Display data types of columns\n",
    "print(\"\\nSummary statistics for Ratings dataset:\")\n",
    "ratings_df.describe().show()\n",
    "\n",
    "# Display basic statistics and data types for the Users dataset\n",
    "print(\"\\nUsers dataset statistics and data types:\")\n",
    "print(\"\\nData types in Users dataset:\")\n",
    "print(users_df.dtypes)  # Display data types of columns\n",
    "print(\"\\nSummary statistics for Users dataset:\")\n",
    "users_df.describe().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d186db04-c827-494f-a00e-e1789ed691fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined Books and Ratings data:\n+----------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------+-----------+\n|      ISBN|          Book-Title|        Book-Author|Year-Of-Publication|           Publisher|         Image-URL-S|         Image-URL-M|         Image-URL-L|User-ID|Book-Rating|\n+----------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------+-----------+\n|0671002481|The First Wives C...|   Olivia Goldsmith|               1996|              Pocket|http://images.ama...|http://images.ama...|http://images.ama...| 271593|          0|\n|0842329129|Left Behind: A No...|         Tim Lahaye|               1996|Tyndale House Pub...|http://images.ama...|http://images.ama...|http://images.ama...| 274634|          0|\n|3423620005|Sofies Welt. Roma...|    Jostein Gaarder|               1999|                 Dtv|http://images.ama...|http://images.ama...|http://images.ama...| 199827|          0|\n|0174434642|Othello (3rd Series)|William Shakespeare|               1996|Thomas Nelson Pub...|http://images.ama...|http://images.ama...|http://images.ama...| 250367|          0|\n|0446606723|           Wild Seed|  Octavia E. Butler|               1999|              Aspect|http://images.ama...|http://images.ama...|http://images.ama...| 268434|          5|\n+----------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------+-----------+\nonly showing top 5 rows\n\nJoined Users and Ratings data:\n+-------+----------+-----------+--------------------+---+\n|User-ID|      ISBN|Book-Rating|            Location|Age|\n+-------+----------+-----------+--------------------+---+\n| 276725|034545104X|          0|   tyler, texas, usa| 34|\n| 276726|0155061224|          5|seattle, washingt...| 34|\n| 276727|0446520802|          0|h, new south wale...| 16|\n| 276729|052165615X|          3|rijeka, n/a, croatia| 16|\n| 276729|0521795028|          6|rijeka, n/a, croatia| 16|\n+-------+----------+-----------+--------------------+---+\nonly showing top 5 rows\n\nComplete data join:\n+-------+----------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+---+\n|User-ID|      ISBN|          Book-Title|        Book-Author|Year-Of-Publication|           Publisher|         Image-URL-S|         Image-URL-M|         Image-URL-L|Book-Rating|            Location|Age|\n+-------+----------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+---+\n| 271593|0671002481|The First Wives C...|   Olivia Goldsmith|               1996|              Pocket|http://images.ama...|http://images.ama...|http://images.ama...|          0|warren, pennsylva...| 34|\n| 274634|0842329129|Left Behind: A No...|         Tim Lahaye|               1996|Tyndale House Pub...|http://images.ama...|http://images.ama...|http://images.ama...|          0|wahiawa, hawaii, usa| 33|\n| 199827|3423620005|Sofies Welt. Roma...|    Jostein Gaarder|               1999|                 Dtv|http://images.ama...|http://images.ama...|http://images.ama...|          0|bochum, nordrhein...| 34|\n| 250367|0174434642|Othello (3rd Series)|William Shakespeare|               1996|Thomas Nelson Pub...|http://images.ama...|http://images.ama...|http://images.ama...|          0|denver, colorado,...| 34|\n| 268434|0446606723|           Wild Seed|  Octavia E. Butler|               1999|              Aspect|http://images.ama...|http://images.ama...|http://images.ama...|          5|raleigh, north ca...| 34|\n+-------+----------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Join Books and Ratings data based on ISBN\n",
    "book_ratings_df = books_df.join(ratings_df, on=\"ISBN\", how=\"inner\")\n",
    "print(\"Joined Books and Ratings data:\")\n",
    "book_ratings_df.show(5)\n",
    "\n",
    "# Join Users and Ratings data based on User-ID\n",
    "user_ratings_df = ratings_df.join(users_df, on=\"User-ID\", how=\"inner\")\n",
    "print(\"Joined Users and Ratings data:\")\n",
    "user_ratings_df.show(5)\n",
    "\n",
    "# Combine all three datasets using ISBN and User-ID\n",
    "complete_df = book_ratings_df.join(users_df, on=\"User-ID\", how=\"inner\")\n",
    "print(\"Complete data join:\")\n",
    "complete_df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de4a1487-438b-47a3-afef-82ca6b6ebce4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Complete Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "075f95fc-0cc8-4f46-92a6-65477ae3e76f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular books based on total number of ratings received:\n+----------+--------------------+-----+\n|      ISBN|          Book-Title|count|\n+----------+--------------------+-----+\n|0971880107|         Wild Animus| 2496|\n|0316666343|The Lovely Bones:...| 1290|\n|0385504209|   The Da Vinci Code|  881|\n|0060928336|Divine Secrets of...|  730|\n|0312195516|The Red Tent (Bes...|  723|\n|044023722X|     A Painted House|  645|\n|0142001740|The Secret Life o...|  613|\n|067976402X|Snow Falling on C...|  611|\n|0446672211|Where the Heart I...|  583|\n|0671027360| Angels &amp; Demons|  583|\n+----------+--------------------+-----+\nonly showing top 10 rows\n\nMost active users based on number of books rated:\n+-------+-----+\n|User-ID|count|\n+-------+-----+\n|  11676|10915|\n| 198711| 6356|\n| 153662| 5789|\n|  98391| 5776|\n|  35859| 5615|\n| 212898| 4268|\n| 278418| 3956|\n|  76352| 3310|\n| 110973| 2949|\n| 235105| 2920|\n+-------+-----+\nonly showing top 10 rows\n\nBook ratings by user age:\n+---+------------------+\n|Age|        avg_rating|\n+---+------------------+\n|  5| 4.862745098039215|\n|  6| 5.428571428571429|\n|  7|3.5106382978723403|\n|  8|3.8943396226415095|\n|  9|1.1348814229249011|\n| 10|3.6266666666666665|\n| 11|2.8408644400785854|\n| 12|3.8344640434192674|\n| 13| 3.416256157635468|\n| 14| 3.582306477093207|\n| 15| 3.802686280780301|\n| 16| 4.410043130006161|\n| 17|3.9330391404451266|\n| 18|3.2689222183467037|\n| 19|3.8219976680917216|\n| 20|3.5545440276251767|\n| 21| 2.605511093101003|\n| 22|  3.03441876159946|\n| 23|2.7225113858165257|\n| 24|2.7318769163381518|\n+---+------------------+\nonly showing top 20 rows\n\nBook ratings by user location:\n+--------------------+----------+\n|            Location|avg_rating|\n+--------------------+----------+\n|breaux bridge, lo...|      10.0|\n|paderno dugnano, ...|      10.0|\n|14971 deception r...|      10.0|\n|wels, oberösterre...|      10.0|\n|  br, louisiana, usa|      10.0|\n|dublin, georgia, usa|      10.0|\n|   la verne, ca, usa|      10.0|\n|maimi lakes, flor...|      10.0|\n|island lake il., ...|      10.0|\n|auckland, na, new...|      10.0|\n+--------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze the most popular books based on total number of ratings received\n",
    "print(\"Most popular books based on total number of ratings received:\")\n",
    "complete_df.groupBy(\"ISBN\", \"Book-Title\").count().orderBy(desc(\"count\")).show(10)\n",
    "\n",
    "# Examine the most active users based on the number of books rated\n",
    "print(\"Most active users based on number of books rated:\")\n",
    "complete_df.groupBy(\"User-ID\").count().orderBy(desc(\"count\")).show(10)\n",
    "\n",
    "# Analyze book ratings by user age and location\n",
    "print(\"Book ratings by user age:\")\n",
    "complete_df.groupBy(\"Age\").agg(mean(\"Book-Rating\").alias(\"avg_rating\")).orderBy(\"Age\").show()\n",
    "\n",
    "print(\"Book ratings by user location:\")\n",
    "complete_df.groupBy(\"Location\").agg(mean(\"Book-Rating\").alias(\"avg_rating\")).orderBy(desc(\"avg_rating\")).show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9dab068-10b4-41c9-80fc-44ea953cfb45",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Identify Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cb02d4b-8ea2-4c7e-9aa7-7768c57b1cc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in User Age:\n+-------+------------------+\n|summary|               Age|\n+-------+------------------+\n|  count|           1014122|\n|   mean| 36.38844931872102|\n| stddev|10.875290030533929|\n|    min|                 5|\n|    25%|                31|\n|    50%|                34|\n|    75%|                41|\n|    max|               118|\n+-------+------------------+\n\nOutliers in Book Rating:\n+-------+------------------+\n|summary|       Book-Rating|\n+-------+------------------+\n|  count|           1014122|\n|   mean|  2.83427634939386|\n| stddev|3.8530030679781424|\n|    min|                 0|\n|    25%|                 0|\n|    50%|                 0|\n|    75%|                 7|\n|    max|                10|\n+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Identify outliers in User Age\n",
    "print(\"Outliers in User Age:\")\n",
    "complete_df.select(\"Age\").summary().show()\n",
    "\n",
    "# Identify outliers in Book Rating\n",
    "print(\"Outliers in Book Rating:\")\n",
    "complete_df.select(\"Book-Rating\").summary().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4d59830-566c-4977-8bce-333b5e851479",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "951bc4bf-9e42-451a-b983-272895f3db90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between age and book ratings:\nCorrelation: -0.022934210623970143\n"
     ]
    }
   ],
   "source": [
    "# Compute correlation between age and book ratings\n",
    "print(\"Correlation between age and book ratings:\")\n",
    "correlation = complete_df.select(F.corr(\"Age\", \"Book-Rating\")).collect()[0][0]\n",
    "print(f\"Correlation: {correlation}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d64c200-b9b0-43af-8e7a-cfbc36d8d274",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### User Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e59295-9f80-4af0-bacb-7d0c21420da3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book ratings by age groups:\n+---------+------------------+\n|age_group|        avg_rating|\n+---------+------------------+\n|        0|1.9832285115303983|\n|       10|3.6899890976720324|\n|       20|  2.84975523495288|\n|       30|  2.82758246043587|\n|       40|2.7265694792776456|\n|       50|2.8735996526270084|\n|       60| 2.349170865169664|\n|       70| 4.473752012882447|\n|       80|3.0348675034867503|\n|       90|2.9692307692307693|\n|      100|2.5444444444444443|\n|      110|1.3027806385169929|\n+---------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Compare book ratings given by different age groups\n",
    "print(\"Book ratings by age groups:\")\n",
    "\n",
    "# Group ages by decades using floor division\n",
    "age_groups = complete_df.withColumn(\"age_group\", F.floor(col(\"Age\") / 10) * 10)\n",
    "\n",
    "# Calculate the average rating for each age group\n",
    "average_ratings_by_age_group = age_groups.groupBy(\"age_group\").agg(F.mean(\"Book-Rating\").alias(\"avg_rating\")).orderBy(\"age_group\")\n",
    "\n",
    "# Display the results\n",
    "average_ratings_by_age_group.show()\n",
    "\n",
    "# Insight:\n",
    "# Grouping user age into categories (e.g., decades) allows for more meaningful comparisons of book ratings.\n",
    "# This can reveal trends or preferences across different age groups.\n",
    "# Consider using other age groupings (e.g., age bins) depending on the data distribution and specific analysis goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c2cde81-5ccc-4f10-9870-743aae1f5692",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb1a980-6f03-4c8e-ab1f-e06d1663a8fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishers with highest average book ratings:\n+--------------------+----------+\n|           Publisher|avg_rating|\n+--------------------+----------+\n|Colour Energy Cor...|      10.0|\n|Macdonald and Jane's|      10.0|\n|Scribes Valley Pu...|      10.0|\n|        Bourget Bros|      10.0|\n|           D. Spears|      10.0|\n|         Veritas Pub|      10.0|\n|          Veritas Pr|      10.0|\n|Unity School of C...|      10.0|\n|         Hermetic Pr|      10.0|\n|         Sopris West|      10.0|\n| Indigo Publications|      10.0|\n|           Jugglebug|      10.0|\n|    Providence Press|      10.0|\n|           Sattre Pr|      10.0|\n|          I.P.A.C.S.|      10.0|\n|         Paper Tiger|      10.0|\n|    Arden Publishers|      10.0|\n|Malice Aforethoug...|      10.0|\n|  Wallbuilders Press|      10.0|\n|Helwig Industries...|      10.0|\n+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Explore which publishers receive the highest average book ratings\n",
    "print(\"Publishers with highest average book ratings:\")\n",
    "publisher_ratings = complete_df.groupBy(\"Publisher\").agg(mean(\"Book-Rating\").alias(\"avg_rating\"))\n",
    "top_publishers = publisher_ratings.orderBy(desc(\"avg_rating\")).show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32b531b1-75a9-4360-b6a7-9fc34b048899",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Books with Highest/ Lowest Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c14d7397-f5ff-47c2-9726-7cb62d7566a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with highest average ratings:\n+----------+--------------------+----------+\n|      ISBN|          Book-Title|avg_rating|\n+----------+--------------------+----------+\n|1886411999|Absolute OpenBSD:...|      10.0|\n|0525938508|Life on the Color...|      10.0|\n|0945367198|Freaks, Geeks and...|      10.0|\n|0425105156|Accent on Desire ...|      10.0|\n|080482052X|Blue and White Japan|      10.0|\n|067088782X|Woman's Day Craft...|      10.0|\n|0690041535|Yankee Doodle's L...|      10.0|\n|156987512X|The Town Mouse an...|      10.0|\n|0394731271|Western Forests (...|      10.0|\n|0859051595|Yammatji: Aborigi...|      10.0|\n+----------+--------------------+----------+\nonly showing top 10 rows\n\nBooks with lowest average ratings:\n+----------+--------------------+----------+\n|      ISBN|          Book-Title|avg_rating|\n+----------+--------------------+----------+\n|0571193307|Aunt Margaret's L...|       0.0|\n|0373164300|Charity'S Angel (...|       0.0|\n|0373163177|Of Dreams And Mag...|       0.0|\n|0307001296|Tweety and Sylves...|       0.0|\n|0394888103|Play-Along and Co...|       0.0|\n|0590313088|            Hideaway|       0.0|\n|0590447769|       New Baby Calf|       0.0|\n|0769602770|         Tweeted Pan|       0.0|\n|0394826639|The Comic Book My...|       0.0|\n|0674373502|Harvard Brief Dic...|       0.0|\n+----------+--------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Identify books with the highest average ratings\n",
    "print(\"Books with highest average ratings:\")\n",
    "complete_df.groupBy(\"ISBN\", \"Book-Title\").agg(mean(\"Book-Rating\").alias(\"avg_rating\")).orderBy(desc(\"avg_rating\")).show(10)\n",
    "\n",
    "# Identify books with the lowest average ratings\n",
    "print(\"Books with lowest average ratings:\")\n",
    "complete_df.groupBy(\"ISBN\", \"Book-Title\").agg(mean(\"Book-Rating\").alias(\"avg_rating\")).orderBy(\"avg_rating\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b14b2b4-bca7-4ed6-be01-02fd6ce5acc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba11b0ac-38f7-41b0-bd96-52f9b2b17970",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ISBN values:\n266667\nUnique User-ID values:\n277233\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique ISBN values in the Books dataset\n",
    "print(\"Unique ISBN values:\")\n",
    "print(books_df.select(\"ISBN\").distinct().count())\n",
    "\n",
    "# Calculate the number of unique User-ID values in the Users dataset\n",
    "print(\"Unique User-ID values:\")\n",
    "print(users_df.select(\"User-ID\").distinct().count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42052fc2-529a-44fc-85c8-c3f15015c791",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Frequent Book- User Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "129c5b08-d062-46b0-af79-4c189cff805a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent book-user pairs:\n+-------+----------+-----+\n|User-ID|      ISBN|count|\n+-------+----------+-----+\n| 277375|3548603203|    1|\n| 276936|0749317256|    1|\n| 276733|2080674722|    1|\n| 276798|3548603203|    1|\n| 276964|0515131520|    1|\n| 276798|3499134004|    1|\n| 277427|0425087859|    1|\n| 277378|0767906373|    1|\n| 277157|0441005470|    1|\n| 276904|0738205737|    1|\n+-------+----------+-----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze which books and users appear together most frequently\n",
    "print(\"Frequent book-user pairs:\")\n",
    "# Group by 'User-ID' and 'ISBN' to find the frequency of each book-user pair\n",
    "frequent_pairs = complete_df.groupBy(\"User-ID\", \"ISBN\").count()\n",
    "\n",
    "# Order the pairs in ascending order of count\n",
    "frequent_pairs.orderBy(\"count\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1564d61-ec27-40ce-bbce-e395a5e36d96",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66911dac-dceb-484e-a43c-f0c9ce5d1ec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the user ID for recommendations:  123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendation candidates for User ID 123 (Age Group: 20s):\n+----------+--------------------+----------+\n|      ISBN|          Book-Title|avg_rating|\n+----------+--------------------+----------+\n|0060923288|Raising Your Spir...|      10.0|\n|0060173890|Frankly Scarlett,...|      10.0|\n|8478445137|        de Profundis|      10.0|\n|1558506454|Museum of Science...|      10.0|\n|1593080409|The Complete Sher...|      10.0|\n|0385260458|Anthills of the S...|      10.0|\n|0811201856|A Season in Hell ...|      10.0|\n|0140309128|Danny, the Champi...|      10.0|\n|0890877254|The Totally Garli...|      10.0|\n|0440226236|       The Death Pit|      10.0|\n+----------+--------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "##### Recommendation Based on User Age and Book Ratings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ask for user ID input to recommend books\n",
    "user_id = int(input(\"Enter the user ID for recommendations: \"))\n",
    "\n",
    "# Get the user's age from the Users dataset\n",
    "user_age_row = users_df.filter(users_df[\"User-ID\"] == user_id).select(\"Age\").collect()\n",
    "\n",
    "# Check if the user was found in the dataset\n",
    "if user_age_row:\n",
    "    user_age = user_age_row[0][\"Age\"]\n",
    "\n",
    "    # Create an age_group column by grouping ages by decades\n",
    "    age_group = (int(user_age) // 10) * 10\n",
    "\n",
    "    # Filter the complete dataset for the specified age group\n",
    "    age_group_data = complete_df.filter((complete_df[\"Age\"] >= age_group) & (complete_df[\"Age\"] < age_group + 10))\n",
    "\n",
    "    # Group by ISBN and Book-Title and calculate the average book rating for the user's age group\n",
    "    recommendation_candidates = age_group_data.groupBy(\"ISBN\", \"Book-Title\").agg(mean(\"Book-Rating\").alias(\"avg_rating\")).orderBy(desc(\"avg_rating\"))\n",
    "\n",
    "    # Display the top recommendation candidates for the user's age group\n",
    "    print(f\"Top recommendation candidates for User ID {user_id} (Age Group: {age_group}s):\")\n",
    "    recommendation_candidates.show(10)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"User ID {user_id} not found or invalid age.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12daf21f-fe9b-47f3-b958-a817b6bcb8e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top trending books:\n+----------+--------------------+-----+----+\n|      ISBN|          Book-Title|count|rank|\n+----------+--------------------+-----+----+\n|0971880107|         Wild Animus| 2496|   1|\n|0316666343|The Lovely Bones:...| 1290|   2|\n|0385504209|   The Da Vinci Code|  881|   3|\n|0060928336|Divine Secrets of...|  730|   4|\n|0312195516|The Red Tent (Bes...|  723|   5|\n|044023722X|     A Painted House|  645|   6|\n|0142001740|The Secret Life o...|  613|   7|\n|067976402X|Snow Falling on C...|  611|   8|\n|0446672211|Where the Heart I...|  583|   9|\n|0671027360| Angels &amp; Demons|  583|  10|\n+----------+--------------------+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "##### Trending and Popular Books\n",
    "\n",
    "\n",
    "# Find books with the most recent increase in popularity\n",
    "from pyspark.sql.window import Window\n",
    "trending_books = complete_df.groupBy(\"ISBN\", \"Book-Title\").agg(count(\"User-ID\").alias(\"count\"))\n",
    "trending_books = trending_books.withColumn(\"rank\", F.row_number().over(Window.orderBy(desc(\"count\"))))\n",
    "print(\"Top trending books:\")\n",
    "trending_books.filter(trending_books[\"rank\"] <= 10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84b90666-ec61-4a9c-b38f-4ff1e6ceab21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c09e44c4-5c51-431b-bdab-e3e2ff3a76b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Convert ISBN column from string to numeric values\n",
    "indexer = StringIndexer(inputCol=\"ISBN\", outputCol=\"ISBNIndex\")\n",
    "indexed_df = indexer.fit(complete_df).transform(complete_df)\n",
    "\n",
    "# Prepare the data\n",
    "indexed_df = indexed_df.filter(indexed_df[\"Book-Rating\"] > 0)  # Filter out 0 ratings\n",
    "(training_data, test_data) = indexed_df.randomSplit([0.8, 0.2])  # Split data into training and test sets\n",
    "\n",
    "# Initialize ALS model\n",
    "als = ALS(\n",
    "    maxIter=2,  # Number of iterations to run the algorithm\n",
    "    regParam=0.1,  # Regularization parameter to avoid overfitting\n",
    "    userCol=\"User-ID\",  # Column representing users\n",
    "    itemCol=\"ISBNIndex\",  # Column representing items (books) after indexing\n",
    "    ratingCol=\"Book-Rating\",  # Column representing ratings\n",
    "    coldStartStrategy=\"drop\"  # Strategy to handle cold start (unknown users/items)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86ae247-5f75-4b8a-bdb2-c8b15a697a81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 8.104666694617759\nTop 10 book recommendations for each user:\n+-------+--------------------+\n|User-ID|     recommendations|\n+-------+--------------------+\n|     12|[{8196, 12.113528...|\n|     16|[{49021, 20.95031...|\n|     22|[{5661, 8.119773}...|\n|     26|[{7777, 28.627188...|\n|     44|[{14725, 8.143021...|\n+-------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Train the ALS model\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"Book-Rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "predictions = model.transform(test_data)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")\n",
    "\n",
    "# Make book recommendations for each user\n",
    "print(\"Top 10 book recommendations for each user:\")\n",
    "user_recommendations = model.recommendForAllUsers(10)\n",
    "user_recommendations.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c65895e8-098b-4c4a-a328-111aa2d637dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 book recommendations (titles) for each user:\n+-------+-------------------------------------+\n|User-ID|Book-Title                           |\n+-------+-------------------------------------+\n|252356 |Harry Potter und der Stein der Weisen|\n|216057 |Harry Potter und der Stein der Weisen|\n|94781  |Harry Potter und der Stein der Weisen|\n|215829 |Harry Potter und der Stein der Weisen|\n|125878 |Harry Potter und der Stein der Weisen|\n|109620 |Harry Potter und der Stein der Weisen|\n|74272  |Harry Potter und der Stein der Weisen|\n|274831 |Harry Potter und der Stein der Weisen|\n|248607 |Harry Potter und der Stein der Weisen|\n|235055 |Harry Potter und der Stein der Weisen|\n|209147 |Harry Potter und der Stein der Weisen|\n|26143  |Harry Potter und der Stein der Weisen|\n|261941 |Blackout                             |\n|228508 |Blackout                             |\n|219153 |Blackout                             |\n|216932 |Blackout                             |\n|208590 |Blackout                             |\n|186229 |Blackout                             |\n|177454 |Blackout                             |\n|174506 |Blackout                             |\n+-------+-------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Make book recommendations for each user\n",
    "user_recommendations = model.recommendForAllUsers(5)  # Recommend 5 books for each user\n",
    "\n",
    "# Explode the recommendations array to get individual recommendations\n",
    "exploded_recommendations = user_recommendations \\\n",
    "    .withColumn(\"recommendation\", explode(user_recommendations[\"recommendations\"])) \\\n",
    "    .select(col(\"User-ID\"), col(\"recommendation.ISBNIndex\").alias(\"ISBNIndex\"))\n",
    "\n",
    "# Join with indexed_df to get the complete book titles based on ISBNIndex\n",
    "user_recommendations_with_titles = exploded_recommendations \\\n",
    "    .join(indexed_df, \"ISBNIndex\") \\\n",
    "    .select(exploded_recommendations[\"User-ID\"], indexed_df[\"Book-Title\"])\n",
    "\n",
    "# Show 5 recommendations of book titles for each user\n",
    "print(\"Top 5 book recommendations (titles) for each user:\")\n",
    "user_recommendations_with_titles.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Book Recommendation System Project",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
